{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN24nsZu7fi1DnPgtwSo5ip",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manikanta898/Spam-SMS-Detection/blob/main/Spam_SMS_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vncDsAP0Gaoa"
      },
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beRrZCGUAJYm"
      },
      "source": [
        "#### Project Name - SMS Spam Detection\n",
        "#### Project Type - Supervised Learning\n",
        "#### Project by  - Manikanta Tangi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJNUwmbgGyua"
      },
      "source": [
        "# **Project Summary -**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6v_1wHtG2nS"
      },
      "source": [
        "In this supervised machine learning project, the objective is to develop a **classification model** that can accurately distinguish between spam and legitimate (ham) SMS messages. The dataset consists of **5,572 messages**, categorized as **spam (1) or ham (0)**.\n",
        "\n",
        "The project involves **text preprocessing**, including **lowercasing, punctuation removal, stopword removal, and stemming**, to clean and standardize the messages. Using **TF-IDF vectorization**, the text is converted into numerical features, which are then used to train a **Naive Bayes classifier** a commonly used model for text classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQaldy8SH6Dl"
      },
      "source": [
        "# **Problem Statement**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpeJGUA3kjGy"
      },
      "source": [
        "The goal of this project is to **classify SMS messages as spam or non-spam** using machine learning techniques. The model will help in **automatically filtering out spam messages**, reducing user inconvenience and improving security. The project focuses on achieving **high accuracy and efficiency** through proper data preprocessing and the use of effective classification algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RnN4peoiCZX"
      },
      "source": [
        "### Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "outputs": [],
      "source": [
        "# Loading Dataset\n",
        "import pandas as pd\n",
        "path='/content/sms_spam.csv'\n",
        "df = pd.read_csv(path, encoding='latin-1')\n",
        "\n",
        "# Displaying the first few rows and dataset info\n",
        "df.info(), df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PzOExI_dGQK"
      },
      "source": [
        "# **Cleaning the data**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dropping unnecessary columns\n",
        "df = df[['v1', 'v2']]\n",
        "\n",
        "# Renaming columns for clarity\n",
        "df = df.rename(columns={'v1': 'label', 'v2': 'message'})\n",
        "\n",
        "# Converting labels to binary (ham = 0, spam = 1)\n",
        "df['label'] = df['label'].map({'ham': 0, 'spam': 1})\n",
        "\n",
        "# Checking the cleaned dataset\n",
        "df.info(), df.head()"
      ],
      "metadata": {
        "id": "XYSwaJEKdL4U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Kept only relevant columns (v1, v2).\n",
        "- Renamed them as label, message for clarity.\n",
        "- Converted the labels (ham → 0, spam → 1)."
      ],
      "metadata": {
        "id": "lvuGXHW4lNtW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk0dfHPTduTa"
      },
      "source": [
        "# **Text Preprocessing**\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "# Downloading stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Initialing the stemmer and stopwords\n",
        "ps = PorterStemmer()\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Text preprocessing function\n",
        "def preprocess_text(text):\n",
        "    # Converting to lowercase\n",
        "    text = text.lower()\n",
        "    # Removing special characters, numbers, and punctuation\n",
        "    text = re.sub(r'[^a-z\\s]', '', text)\n",
        "    # Tokenization and stemming\n",
        "    words = text.split()\n",
        "    words = [ps.stem(word) for word in words if word not in stop_words]\n",
        "    # Joining the words back into a cleaned sentence\n",
        "    return ' '.join(words)\n",
        "\n",
        "# Applying preprocessing to all messages\n",
        "df['cleaned_message'] = df['message'].apply(preprocess_text)\n",
        "\n",
        "# Displaying the cleaned dataset\n",
        "df.head()"
      ],
      "metadata": {
        "id": "HuV-sbrIduTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- All messages are converted to lowercase, punctuation removed, and stopwords filtered out.\n",
        "- Stemming applied to reduce words to their root form (e.g., 'running' → 'run').\n",
        "- The dataset is now ready for feature extraction."
      ],
      "metadata": {
        "id": "77JAp0J7hi25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Converting text into numerical features using TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=5000)  # Limit features to 5000 most important words\n",
        "X = tfidf_vectorizer.fit_transform(df['cleaned_message'])\n",
        "\n",
        "# Labels (Spam = 1, Ham = 0)\n",
        "y = df['label']\n",
        "\n",
        "# Splitting the dataset into 80% training and 20% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Checking dataset sizes\n",
        "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
      ],
      "metadata": {
        "id": "DwI7LQLTec_8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- Text successfully converted into numerical features using TF-IDF.\n",
        "- Dataset split into 80% training and 20% testing.\n",
        "- The model is now ready for training."
      ],
      "metadata": {
        "id": "dh6rwdd6h2LQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Training a Naive Bayes model\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train, y_train)\n",
        "\n",
        "# Predictions on the test set\n",
        "y_pred = nb_model.predict(X_test)\n",
        "\n",
        "# Evaluating the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "classification_rep = classification_report(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Printing the results\n",
        "print(f\"Model Accuracy: {accuracy:.2%}\\n\")\n",
        "print(\"Classification Report:\\n\", classification_rep)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "FkCtm-VremLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Algorithm Used: Naive Bayes (MultinomialNB)\n",
        "- Accuracy Achieved: 96.77%\n",
        "- Precision (Spam Detection): 99% (Very few false positives)\n",
        "- Recall (Spam Detection): 77% (Some spam messages missed)\n",
        "- Confusion Matrix Analysis: 35 spam messages misclassified as ham."
      ],
      "metadata": {
        "id": "TOzo7kzzi6UY"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b870N2RgVAn"
      },
      "source": [
        "# **Conclusion**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This project successfully showed how to classify text using Machine Learning.This method could be used in real-world applications like filtering spam in messages, emails, and detecting fraud."
      ],
      "metadata": {
        "id": "VBU_DymmgaIz"
      }
    }
  ]
}